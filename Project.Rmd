---
title: "Bayesian Methods Final Project"
subtitle: "SESGO DE GÉNERO EN EL RENDIMIENTO ACADÉMICO EN LA MATERIA DE MATEMÁTICAS"
author:
- Aráiztegui, Aránzazu
- Ferrara, Lorenzo
- Lucchini, Marco
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document: 
    fig_caption: yes
    number_sections: true
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
    theme: united
    highlight: tango
header-includes:
- \pagenumbering{gobble}
- \usepackage{subfig}
- \usepackage[labelsep=period]{caption}
- \usepackage[labelfont=bf]{caption}
- \renewcommand{\and}{\\}
---


\renewcommand{\contentsname}{Índice}
\renewcommand{\figurename}{Figura}
\renewcommand{\tablename}{Tabla}

\captionsetup{width=.75\textwidth}

\vspace{120mm}

<left>
![](Logo UPC.png){width="50%"}
</left> <right>
![](Logo UB.png){width="50%"}
</right> 

\newpage

\tableofcontents

\pagebreak

\pagenumbering{arabic}


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
knitr::opts_chunk$set(out.width = '70%')
knitr::opts_chunk$set(fig.align = "center")
# knitr::opts_chunk$set(results = "hide")
# knitr::opts_chunk$set(message =FALSE)
library(knitr)
library(kableExtra)
library(summarytools)
library(ggplot2)
library(fastDummies)
library(R2jags)
library(truncnorm)
```

```{r load}
load("alumni.Rdata")
alumni$AREA_TERRITORIAL[alumni$AREA_TERRITORIAL == "Maresme Vallès Oriental" | alumni$AREA_TERRITORIAL == "Maresme-Vallès Oriental"] = "Maresme - Vallès Oriental" 

alumni$AREA_TERRITORIAL = factor(alumni$AREA_TERRITORIAL)
```




# Introducción 

El sesgo de género está presente en numerosos ámbitos de nuestra vida y se aprecia de forma notable en el ámbito educativo, más concretamente en las materias del ámbito STEAM. 
\
Parece ser que aunque no hay una evidente brecha de género en el comienzo de los estudios primarios, el sesgo de género comienza a aparecer de forma clara a lo largo del proceso educativo, agudizándose en las últimas etapas de la educación obligatoria y evidenciándose de forma clara en la educación universitaria.

## Descripción del problema

Con el objetivo de evaluar la capacidad y el nivel de competencia en las diferentes áreas del conocimiento que tiene el alumnado de Cataluña, el Departament d’Educació de la Generalitat de Cataluña realiza una prueba de competencias y conocimientos básicos en las áreas lingüísticas, matemáticas y científico-tecnológicas en los últimos cursos de la educación primaria y secundaria.
\
Según el Departament se trata de una evaluación de carácter formativo y orientador que pueda servir tanto a los centros como al profesorado y al propio Departament para impulsar las mejoras en el sistema educativo catalán.


## Objectivos del modelo

Este trabajo tiene como objetivo principal ver si existe un sesgo de género en los resultados obtenidos en la competencia matemática con respecto al sexo y a las competencias humanísticas para ello intentaremos crear un modelo que relacione la puntuación obtenida en la competencia matemática con respecto al sexo, a las competencias lingüísticas e incluso con respecto al tipo de centro educativo o al tamaño de la población. 
\
De esta manera podríamos ver si en el sexo femenino no se da una diferencia entre el rendimiento en humanidades y matemáticas, personas con bajo rendimiento en humanidades también lo tendrían en matemáticas. 
\
Y en cambio en el sexo masculino personas con bajo rendimiento en humanidades tendrían buenos resultados en matemáticas.
\
Si ampliamos los datos y vemos la tabla de resultados para un mismo individuo en sexto de primaria y cuarto de la podríamos establecer un segundo objetivo que sería ver si se mantienen los resultados en ambos sexos o si hay diferencias significativas en cuanto al rendimiento en el área de matemáticas al aumentar la edad.


\newpage

# Descripción de la base de datos

La base de datos utilizada es una mezcla de los datos ofrecidos para cuarto curso de ESO y los datos que se ofrecen para sexto curso de primaria. La razón de realizar la fusión de las dos tablas es poder evaluar la evolución de una misma persona desde el final de la educación primaria hasta el final de la educación secundaria. Se puede acceder a la base de datos completa en el siguiente enlace:
\
[Avaluació de quart d’Educació Secundària Obligatòria | Dades obertes de Catalunya](https://analisi.transparenciacatalunya.cat/Educaci-/Avaluaci-de-quart-d-Educaci-Secund-ria-Obligat-ria/59vm-wwq7)

[Avaluació de sisè d'educació primària | Dades obertes de Catalunya](https://analisi.transparenciacatalunya.cat/Educaci-/Avaluaci-de-sis-d-educaci-prim-ria/rk5x-gny6)
\
El dataset contiene los resultados obtenidos por el alumnado de cuarto curso de ESO y los datos que se ofrecen para sexto curso de primaria en la evaluación de competencias básicas desde el año 2012.
\
El código de alumno se utilizó para hacer comparativas con los resultados obtenidos.
\
La base de datos ha sido actualizada el 20 de octubre de 2022 y contiene los datos de 46384 estudiantes.



## Definición de las variables utilizadas

Base de dades 

| Nom de columna | Descripció | Tipus |
|--------------------|-----------------------------------------------|----------------|
| PMAT_4 | Puntuació global ponderada de competència matemàtica en el examen de Quart | Nombre |
| PMAT_6 | Puntuació global ponderada de competència matemàtica en el examen de Sisè | Nombre |
| PLENG_4 | Puntuació global ponderada de la competència lingüística en llengua catalana y castellana en el examen de Quart | Nombre |
| PLENG_6 | Puntuació global ponderada de la competència lingüística en llengua catalana y castellana en el examen de Sisè | Nombre |
| PANG_4 | Puntuació global ponderada de la competència lingüística en llengua anglesa en el examen de Quart | Nombre |
| PANG_6 | Puntuació global ponderada de la competència lingüística en llengua anglesa en el examen de Sisè | Nombre |
| GENERE | Gènere de l’alumne/a que es presenta a l’avaluació | Text Pla |
| AREA_TERRITORIAL | Regió on es troba el centre de l’alumne/a que es presenta a l’avaluació | Text Pla |
| NATURALESA | Determina si el centre de l’alumne/a és públic, privat o concertat | Text Pla |
| HÀBITAT | Municipis per trams de població | Text Pla|



## Análisis exploratorio de los datos

En el análisis inicial de los datos podemos ver que la distribución de hombres y mujeres es uniforme con una proporción de 50,1% niños y 49,9% niñasen. 
\
La distribución de alumnos por áreas es la siguiente.

```{r his_area, out.width="90%", warning=FALSE, message=FALSE, fig.align='center'}
area = alumni$AREA_TERRITORIAL
ggplot(data.frame(area), aes(x=area)) +
  geom_bar(fill="royalblue3") +
  theme(axis.text.x = element_text(angle = 335, vjust = 1, hjust=0)) +
  theme(plot.margin = margin(0,2,0,2, "cm")) +
  ggtitle("Distribución de alumnos entre las áreas", ) + 
  ylab("Número") +
  xlab("Àrea")
```

Según el tamaño de la población los datos de los que disponemos se concentran en individuos de ciudades de tamaño medio o grande.

```{r hist_ciudad, out.width="60%", warning=FALSE, message=FALSE, fig.align='center'}
ciudad = factor(alumni$HÀBITAT, levels = c("Fins a 10000", "De 10001 a 100000", "Més de 100000"))
ggplot(data.frame(ciudad), aes(x=ciudad)) +
  geom_bar(fill="royalblue3") +
  theme(axis.text.x = element_text(angle = 335, vjust = 0.5, hjust=0)) +
  theme(plot.margin = margin(0,1,0,0, "cm")) +
  ggtitle("Distribución de alumnos entre las hàbitat", ) + 
  ylab("Número") +
  xlab("Habitàt")
```

Pasamos ahora a la nota obtenida en el examen de inglés, lengua y matemáticas en el examen de Sisè y Quart. Los grados se dividen entre niños y niñas. Del gráfico suponemos que los chicos tienden a tener peores notas en inglés y lengua mientras que obtienen mejores resultados en matemáticas con respecto a las chicas.

```{r boxplot_sise, out.width="80%", warning=FALSE, message=FALSE, fig.align='center'}
set.seed(1234)
df=alumni[sample(1:length(alumni$PMAT_6), replace = F, size = 4000), ]

library(tidyverse)

df_tmp = df[,c("PMAT_4",   "PMAT_6",  "PLENG_4",   "PLENG_6",   "PANG_4", "PANG_6",  "GENERE")]
keep = c("PMAT_4",   "PMAT_6",  "PLENG_4",   "PLENG_6",   "PANG_4", "PANG_6",  "GENERE")
df2 = df_tmp[,keep] %>%   # select relevant columns 
  pivot_longer(c(1,2,3,4,5,6),names_to = 'Test')



library(ggplot2)
library(GGally)
ggplot(data = df2, aes(x=GENERE,y=value, fill=GENERE)) + 
  geom_boxplot()+
#  scale_fill_brewer(palette="Green") + 
#  geom_jitter(shape=16, position=position_jitter(0.2))+
  labs(title = 'Comparación de resultados educativos por género',
       y='Notas',x='') +
  facet_wrap(~Test,nrow = 1)
```


En el siguiente gráfico podemos ver las diferencias entre las calificaciones en matemáticas, inglés y lengua de cada sexo dependiendo del nivel educativo. Si comparamos la misma asignatura en los dos cursos los datos muestran una distribución casi lineal y con poca variabilidad, lo cual nos hace pensar que el alumnado que obtiene buenos resultados en sexto de primaria también obtienen buenos resultados al acabar la secundaria, como cabría esperar.
También cabe destacar la distribución de las frecuencias por género, en especial en el caso de matemáticas donde parece observarse una diferencia más evidente entre chicos y chicas.

```{r ggpairs_sise, out.width="90%", fig.align='center', cache=TRUE}
keep = c("PMAT_4",   "PMAT_6",  "PLENG_4",   "PLENG_6",   "PANG_4", "PANG_6",  "GENERE")
set.seed(1999)
df_sampl <- df[sample(1:dim(df)[1], 1000), keep]

# Different aesthetics for different plot sections and plot types
my_dens <- function(data, mapping, ...) {
  ggplot(data = data, mapping=mapping) +
    geom_density(..., mapping = ggplot2::aes(color = GENERE, alpha = 0.7), fill=NA) 
}

ggpairs(
  df_sampl[,],
  mapping = ggplot2::aes(color = GENERE, alpha = 0.8),
  diag = list(continuous = my_dens),
  upper = list(continuous = wrap("density", alpha = 0.5), combo = "box_no_facet"),
  lower = list(continuous = wrap("points", alpha = 0.3), combo = wrap("dot_no_facet", alpha = 0.4)),
  title = "Comparación de resultados entre sujetos"
)
```



\newpage
# Análisis bayesiano

## Modelo 1

Para describir qué tan bien obtendrá un estudiante en el examen Quart Maths, usamos las calificaciones que obtuvo en los exámenes Sise y las que obtuvo en los exámenes Quart English and Language. Dado que nuestro objetivo es explicar si el género influye en el desempeño de un estudiante, llevándolo a obtener mejores resultados que sus compañeros, utilizamos las calificaciones desde una perspectiva diferencial con respecto al promedio, es decir, $$ MAT_4 = MAT_4 - media(MAT_4) $$ y lo mismo para todos los demás grados utilizados dentro del modelo. También usamos el género del estudiante, la región de origen, el tamaño de la ciudad y la interacción entre el género y los puntajes de los exámenes de idioma de la escuela secundaria en el modelo. Esta última covariable nos ayudará a explicar si los chicos tienen rendimientos opuestos en las dos materias con respecto al rendimiento medio.
\
Se crea un modelo jerárquico con la región de origen para agregar un efecto aleatorio debido al área. Se supone que todas las regiones tienen una distribución normal con media 0 mientras que la varianza cambia para cada una. Sin embargo, se obtiene a partir de una única distribución común a todas las regiones.

### Presentacion del modelo

El modelo utilizado es el siguiente.

$$y_i \sim N( b_0 + mat_4*x^1_i + leng_4 * x^2_i + leng_6 * x^3_i + ing_4*x^4_i + ing^6*x^5_i  + \ publica*x^6_i $$ 
$$+ \ ciudPeq*x^7_i + ciudGrande*x^8_i + sexo_h*x^9_i + interaccion*x^2_i*x^9_i + G[area[i]], tau_y)$$

Suponemos que el coeficiente tiene la siguiente distribución. Elegimos la distribución normal estándar ya que las variables son un sesgo de la media de cada examen.

$$ b_0 \sim  N(0, 1) $$ 
$$ mat_4 \sim N(0, 1)   $$
$$ leng_4 \sim N(0, 1) $$
$$ leng_6 \sim N(0, 1) $$
$$ ing_4 \sim N(0, 1) $$
$$ ing_6 \sim N(0, 1) $$
$$ publica \sim N(0, 1) $$
$$ ciudPeq \sim N(0, 1) $$
$$ ciudGrande \sim N(0, 1) $$
$$ sexo_h \sim N(0, 1) \ \ \ x^9 \ es \ 1 \ si \ es \ hombre$$
$$ interaccion \sim N(0, 1) $$
$$ tau_y \sim \Gamma(0.001, 0.001) $$
$$ sigma_y = \frac{1}{\sqrt{tau_y}} $$
$$ G_i \sim N(0, tau_g) $$
$$ tau_g \sim \Gamma(0.001, 0.001) $$
$$ sigma_g = \frac{1}{\sqrt{tau_g}} $$


```{r prep_mod1}
names(alumni)[4] = "HABITAT"
alumni = dummy_cols(alumni, select_columns = c("NATURALESA", "GENERE", "HABITAT"), remove_first_dummy = T, remove_selected_columns = T)
areas = dummy_cols(data.frame(Area = alumni$AREA_TERRITORIAL), remove_first_dummy = T, remove_selected_columns = T)
names(areas)=levels(alumni$AREA_TERRITORIAL)[-1]
m=dim(areas)[2]

m4 = mean(alumni$PMAT_4)

alumni$PLENG_6 = alumni$PLENG_6 - mean(alumni$PLENG_6)  # Plen_6  = delta_pl_6
alumni$PLENG_4 = alumni$PLENG_4 - mean(alumni$PLENG_4)  # Plen_6  = delta_pl_6
alumni$PANG_6 = alumni$PANG_6 - mean(alumni$PANG_6)  # Plen_6  = delta_pa_6
alumni$PANG_4 = alumni$PANG_4 - mean(alumni$PANG_4)  # Plen_6  = delta_pa_4
alumni$PMAT_6 = alumni$PMAT_6 - mean(alumni$PMAT_6)  # Plen_6  = delta_pa_6
alumni$PMAT_4 = alumni$PMAT_4 - mean(alumni$PMAT_4)  # Plen_6  = delta_pa_6

n = 4000
set.seed(1234)
id_train = sample(1:length(alumni$PMAT_6), replace = F, size = n)
train = alumni[id_train, ]
test = alumni[-id_train, ]

areas_train = areas[id_train, ]
areas_test = areas[-id_train, ]

```


```{r model_1}
mod.alumni.1 <- "
model {

 for (i in 1:n) {
  y[i]~ dnorm(b0 + mat6*x1[i] + leng4*x2[i] + leng6*x3[i] + ing4*x4[i] + ing6*x5[i] + publica*x6[i] + ciud_peq*x7[i] + ciud_grande*x8[i] + sexo*x9[i] + interaccion*x2[i]*x9[i] + sum(G*geo[i,]), tau_y)
 }
 
 b0 ~ dnorm(0, 1)
 mat6 ~ dnorm(0, 1)  
 leng4 ~ dnorm(0, 1)
 leng6 ~ dnorm(0, 1)
 ing4 ~ dnorm(0, 1)
 ing6 ~ dnorm(0, 1)
 publica ~ dnorm(0, 1)
 ciud_peq ~ dnorm(0, 1)
 ciud_grande ~ dnorm(0, 1)
 sexo ~ dnorm(0, 1)
 interaccion ~ dnorm(0, 1)

 tau_y ~ dgamma(0.001, 0.001)
 sigma_y <- 1/sqrt(tau_y)
 
 for(i in 1:m) {
  G[i] ~ dnorm(0, tau_g)
 }
 
 tau_g ~ dgamma(0.001, 0.001)
  sigma_g <- 1/sqrt(tau_g)
}
"

Iter <- 5000
Burn <- 400
Chain <- 2
Thin <- 1 # per eliminare l'effetto dell'autocorrelazione delle simulazioni

data.1 <- list(y = train$PMAT_4, x1 = train$PMAT_6, x2=train$PLENG_4, x3=train$PLENG_6, x4=train$PANG_4, x5=train$PANG_6, x6=train$NATURALESA_Pública, x7=train$`HABITAT_Fins a 10000`, x8=train$`HABITAT_Més de 100000`, x9=train$GENERE_H, geo= areas_train, n = dim(train)[1], m=m)

parameters.1 <- c("b0", "mat6", "leng4", "leng6", "ing4", "ing6", "publica", "ciud_peq", "ciud_grande", "sexo", "interaccion", "sigma_y", "sigma_g", "G")

initials.1=list(list(b0 = 3, mat6 = 1, leng4= 0.1, leng6=0, ing4=0, ing6=0, publica=0, ciud_peq=0,ciud_grande=0,sexo=0,interaccion=0,
                   tau_y = 4, tau_g= 4, G=rep(0,m)),
              list(b0 = 2, mat6 = 1.5, leng4= 0.2 , leng6=0, ing4=1, ing6=1, publica=1, ciud_peq=1, ciud_grande=1,sexo=1,interaccion=1,
                   tau_y = 2, tau_g = 2, G=rep(0,m)))
```

### Simulación de modelo

Ejecutamos nuestro modelo en un conjunto de datos de prueba de $4 \ 000$ estudiantes. Usamos el paquete `JAGS` para realizar simulaciones utilizando algoritmos de MCMC ya que realizar el problema analíticamente sería casi imposible.
\
Usando dos cadenas diferentes de 5000 iteraciones de largo y eliminando las primeras 400 iteraciones, obtenemos los siguientes resultados. Como puede ver, las dos cadenas convergen y, por lo tanto, el resultado de nuestro modelo es estable.

```{r fit_1, cache=T, message=FALSE, results='hide'}
alumni.sim.1 <- jags(data.1, inits=initials.1, parameters.to.save=parameters.1, 
		  n.iter=(Iter*Thin+Burn),n.burnin=Burn, n.thin=Thin, n.chains=Chain, 
		  model=textConnection(mod.alumni.1))
```

```{r traceplot_1}
par(mar = c(2, 2, 2, 2))
traceplot(alumni.sim.1, mfrow = c(4,3), varname = parameters.1, col=c("black","red"), ask=F)
```

### Interpretación y validación de los modelos

Los coeficientes obtenidos de nuestro modelo tienen las siguientes distribuciones. Si bien las distribuciones relativas a los votos parecen muy cercanas a cero, todas son significativas, el rango tan reducido se debe al valor de los votos que varía en un rango de alrededor de $\pm 30$ votos.
\ 
Sin embargo, es interesante observar que el efecto aleatorio debido a todas las regiones tiene una distribución centrada alrededor de 0. Lo mismo ocurre con el tamaño de la ciudad. Por lo tanto, no podemos considerar su contribución relevante dentro del modelo y, posteriormente, intentaremos eliminar su contribución.

```{r CI_param_1}
output = alumni.sim.1
significance = !(output$BUGSoutput$summary[,3]<0 & output$BUGSoutput$summary[,7]>0)
# print(significance)

linea = which(rownames(output$BUGSoutput$summary)=="deviance")
confid.inter = output$BUGSoutput$summary[-linea,c(3,7,1)]  # small, big, mean

par(mfrow=c(1,1), mar = c(6, 3, 2, 1))
plot(1:length(confid.inter[,1]), confid.inter[,3], col="grey", pch=16, axes = F, xlab="", ylab="", ylim = c(-3,11), main = "Intervalo de confianza del 95% para los coeficientes")
segments(x0=1:length(confid.inter[,1]), y0 = confid.inter[,1], x1 = 1:length(confid.inter[,1]), y1 = confid.inter[,2], lty = 2)
points(1:length(confid.inter[,1]), confid.inter[,3], col="grey", pch=16)
box()
axis(1, 1:length(rownames(confid.inter)), rownames(confid.inter), las = 2)
axis(2, -3:11, -3:11)
points(1:length(confid.inter[,1]), confid.inter[,2], col="red", pch=16)
points(1:length(confid.inter[,1]), confid.inter[,1], col="blue", pch=16)
abline(h=0, lty=2)

```


```{r print_mod1, results='hide'}
print(alumni.sim.1, digits=2)
```


Ahora validamos nuestro modelo usando los cuantiles 25%, 50% y 75% como estadísticas. Estos valores los obtenemos simulando nuestro modelo sobre un subconjunto del testset obtenido como complemento del conjunto de entrenamiento inicial. Nuevamente usamos $4 \ 000$ estudiantes.


```{r prediction}
M = 4000
# M = 10
set.seed(2023)
id_test_pred = sample(1:dim(test)[1],M)
test_pred = test[id_test_pred,-c(2,3)]
areas_test_pred = areas_test[id_test_pred,]
X = cbind(rep(1,n),as.matrix(test_pred), as.matrix(areas_test_pred), as.matrix(test_pred$PLENG_4*(test_pred$GENERE_H)))

C = confid.inter[,3]
C = C[c("b0", "mat6", "leng4", "leng6", "ing4", "ing6", "publica", "sexo", "ciud_peq", "ciud_grande", "G[1]",  "G[2]", "G[3]", "G[4]", "G[5]", "G[6]", "G[7]", "G[8]", "G[9]", "interaccion")]

y_t = rnorm(M, X %*% C, confid.inter["sigma_y",3]) + m4
per <- quantile(y_t, c(0.25, 0.5, 0.75))
# print(per)
# y_t <- rtruncnorm(M, a = -m4 ,b = 100-m4, X %*% C, confid.inter["sigma_y",3]) + m4
# per2 <- quantile(y_t, c(0.25, 0.5, 0.95))
# print(per2)
```

```{r stat_comparison,  message=FALSE}
real <- quantile(train$PMAT_4+m4, c(0.25, 0.5, 0.75))

ggplot() +
  geom_histogram(data=train, aes(x = PMAT_4+m4, y=..density..), color = "grey", fill = "royalblue3") +
  ggtitle("Comparación entre la distribución PMAT_4 y el valor obtenido por las estadísticas", ) +
  geom_vline(xintercept=per[1], linetype="dashed", color = "red", size = 1) +
  geom_vline(xintercept=per[2], linetype="dashed", color = "red", size = 1) + 
  geom_vline(xintercept=per[3], linetype="dashed", color = "red", size = 1) + 
  geom_vline(xintercept=real[1], linetype="dashed", color = "blue", size = 0.5) +
  geom_vline(xintercept=real[2], linetype="dashed", color = "blue", size = 0.5) + 
  geom_vline(xintercept=real[3], linetype="dashed", color = "blue", size = 0.5) + 
  ylab("Densidad") +
  xlab("Nota") 
```

Como puede verse, los tres estadísticos parecen estar bien dispuestos en la distribución de referencia, aunque se mantienen ligeramente por debajo de los valores reales.
\
Intentemos eliminar los efectos de área para que nuestro modelo sea más interpretable.

## Modelo 2 sin areas territoriales

Dado que los coeficientes de las áreas territoriales resultaron con una distribución centrada alrededor de cero, tratamos de eliminar esa covariable del modelo para que sea más fácil de interpretar.

### Presentacion de los modelos 2

Usamos el mismo modelo ilustrado arriba en el que eliminamos las covariables relacionadas con el área geográfica.
Para los coeficientes asumimos siempre una distribución normal estándar para partir de la hipótesis de que los alumnos se comportan con respecto a la media de los alumnos de la misma forma que se comportaron en los demás exámenes.

```{r model_2}
mod.alumni.2 <- "
model {

 for (i in 1:n) {
  y[i]~ dnorm(b0 + mat6*x1[i] + leng4*x2[i] + leng6*x3[i] + ing4*x4[i] + ing6*x5[i] + publica*x6[i] + ciud_peq*x7[i] + ciud_grande*x8[i] + sexo*x9[i] + interaccion*x2[i]*x9[i], tau_y)
 }
 
 b0 ~ dnorm(0, 1)
 mat6 ~ dnorm(0, 1)  
 leng4 ~ dnorm(0, 1)
 leng6 ~ dnorm(0, 1)
 ing4 ~ dnorm(0, 1)
 ing6 ~ dnorm(0, 1)
 publica ~ dnorm(0, 1)
 ciud_peq ~ dnorm(0, 1)
 ciud_grande ~ dnorm(0, 1)
 sexo ~ dnorm(0, 1)
 interaccion ~ dnorm(0, 1)

 tau_y ~ dgamma(0.001, 0.001)
 sigma_y <- 1/sqrt(tau_y)

}
"

Iter <- 5000
Burn <- 400
Chain <- 2
Thin <- 1 #per eliminare l'effetto dell'autocorrelazione delle simulazioni

data.2 <- with(train, list(y = PMAT_4, x1 = PMAT_6, x2=PLENG_4, x3=PLENG_6, x4=PANG_4, x5=PANG_6, x6=NATURALESA_Pública, x7=`HABITAT_Fins a 10000`, x8=`HABITAT_Més de 100000`, x9=GENERE_H, n = dim(train)[1]))

parameters.2 <- c("b0", "mat6", "leng4", "leng6", "ing4", "ing6", "publica", "ciud_peq", "ciud_grande", "sexo", "interaccion", "sigma_y")

initials.2=list(list(b0 = 3, mat6 = 1, leng4= 0.1, leng6=0, ing4=0, ing6=0, publica=0, ciud_peq=0,ciud_grande=0,sexo=0, interaccion=0,
                   tau_y = 4),
              list(b0 = 2, mat6 = 1.5, leng4= 0.2, leng6=0, ing4=1, ing6=1, publica=1, ciud_peq=1, ciud_grande=1,sexo=1, interaccion=1,
                   tau_y = 2))
```

### Simulación de modelo 2

Al igual que hicimos en el modelo anterior, aquí también usamos el paquete JAGS para simular el modelo a través de MCMC. El resultado es el siguiente.

```{R sim_mod2, cache=T, results = "hide"}
alumni.sim.2 <- jags(data.2, inits=initials.2, parameters.to.save=parameters.2, 
		  n.iter=(Iter*Thin+Burn),n.burnin=Burn, n.thin=Thin, n.chains=Chain, 
		  model=textConnection(mod.alumni.2))
```

```{r traceplot_2}
par(mar = c(2, 2, 2, 2))
traceplot(alumni.sim.2, mfrow = c(4,3), varname = parameters.2, col=c("black","red"), ask=F)
```


También en este caso las cadenas convergen y luego procedemos a analizar el modelo.


### Interpretación y validación de los modelos 2

En cuanto al modelo 1, recordamos que las covariables relativas a las notas se expresan en términos de la diferencia entre el resultado y la media. Podemos ver que incluso después de eliminar las covariables relacionadas con el área geográfica, el coeficiente relacionado con la ciudad siempre se distribuye normalmente alrededor de 0.

```{r print_mod_2, results='hide'}
print(alumni.sim.2, digits=2)
```

```{r ci_model2}
output = alumni.sim.2

significance = !(output$BUGSoutput$summary[,3]<0 & output$BUGSoutput$summary[,7]>0)
# print(significance)

linea = which(rownames(output$BUGSoutput$summary)=="deviance")
confid.inter = output$BUGSoutput$summary[-linea,c(3,7,1)]

par(mfrow=c(1,1), mar = c(6, 3, 2, 1))
plot(1:length(confid.inter[,1]), confid.inter[,3], col="grey", pch=16, axes = F, xlab="", ylab="", ylim = c(-3,11), main = "Intervalo de confianza del 95% para los coeficientes")
segments(x0=1:length(confid.inter[,1]), y0 = confid.inter[,1], x1 = 1:length(confid.inter[,1]), y1 = confid.inter[,2], lty = 2)
points(1:length(confid.inter[,1]), confid.inter[,3], col="grey", pch=16)
box()
axis(1, 1:length(rownames(confid.inter)), rownames(confid.inter), las = 2)
axis(2, -3:11, -3:11)
points(1:length(confid.inter[,1]), confid.inter[,2], col="red", pch=16)
points(1:length(confid.inter[,1]), confid.inter[,1], col="blue", pch=16)
abline(h=0, lty=2)
```

Como en el caso anterior, analicemos las estadísticas relativas a los percentiles 25%, 50% y 75%.

```{r prediction2}
M = 4000
# M = 10
set.seed(2023)
id_test_pred = sample(1:dim(test)[1],M)
test_pred = test[id_test_pred,-c(2,3)]
areas_test_pred = areas_test[id_test_pred,]
X = cbind(rep(1,n),as.matrix(test_pred), as.matrix(test_pred$PLENG_4*(test_pred$GENERE_H)))

C = confid.inter[,3]
C = C[c("b0", "mat6", "leng4", "leng6", "ing4", "ing6", "publica", "sexo", "ciud_peq", "ciud_grande", "interaccion")]

y_t = rnorm(M, X %*% C, confid.inter["sigma_y",3]) + m4
per <- quantile(y_t, c(0.25, 0.5, 0.75))
# print(per)
# y_t <- rtruncnorm(M, a = -m4 ,b = 100-m4, X %*% C, confid.inter["sigma_y",3]) + m4
# per2 <- quantile(y_t, c(0.25, 0.5, 0.95))
# print(per2)
```

```{r stat_comparison2,  message=FALSE}
real <- quantile(train$PMAT_4+m4, c(0.25, 0.5, 0.75))

ggplot() +
  geom_histogram(data=train, aes(x = PMAT_4+m4, y=..density..), color = "grey", fill = "royalblue3") +
  ggtitle("Comparación entre la distribución PMAT_4 y el valor obtenido por las estadísticas", ) +
  geom_vline(xintercept=per[1], linetype="dashed", color = "red", size = 1) +
  geom_vline(xintercept=per[2], linetype="dashed", color = "red", size = 1) + 
  geom_vline(xintercept=per[3], linetype="dashed", color = "red", size = 1) + 
  geom_vline(xintercept=real[1], linetype="dashed", color = "blue", size = 0.5) +
  geom_vline(xintercept=real[2], linetype="dashed", color = "blue", size = 0.5) + 
  geom_vline(xintercept=real[3], linetype="dashed", color = "blue", size = 0.5) + 
  ylab("Densidad") +
  xlab("Nota") 
```
El modelo resultante parece ser casi tan fiel como el anterior y además en este caso las estadísticas obtenidas de la simulación con el test set tienen valores ligeramente inferiores a las estadísticas reales.
\
También en este caso se procede a eliminar la covariable de ciudad para obtener un modelo más fácilmente interpretable.

## Modelo 3: quito "ciudad"

Reducimos aún más nuestro modelo manteniendo únicamente las calificaciones obtenidas en los exámenes de Mate, idioma e inglés en los exámenes de Sisè, idioma e inglés en los exámenes de Quart, el género, el tipo de escuela (pública o privada) y la interacción entre género y nota de idioma en Quart.

### Presentacion de los modelos 3

El modelo implementado es el siguiente.


$$y_i \sim N( b_0 + mat_4*x^1_i + leng_4 * x^2_i + leng_6 * x^3_i + ing_4*x^4_i + ing^6*x^5_i  + \ publica*x^6_i + sexo_h*x^9_i + interaccion*x^3_i*x^9_i, tau_y)$$

Suponemos que el coeficiente tiene la siguiente distribución. Elegimos la distribución normal estándar ya que las variables son un sesgo de la media de cada examen.

$$ b_0 \sim  N(0, 1) $$ 
$$ mat_4 \sim N(0, 1)   $$
$$ leng_4 \sim N(0, 1) $$
$$ leng_6 \sim N(0, 1) $$
$$ ing_4 \sim N(0, 1) $$
$$ ing_6 \sim N(0, 1) $$
$$ publica \sim N(0, 1) $$
$$ sexo_h \sim N(0, 1) \ \ \ x^9 \ es \ 1 \ si \ es \ hombre$$
$$ interaccion \sim N(0, 1) $$
$$ tau_y \sim \Gamma(0.001, 0.001) $$
$$ sigma_y = \frac{1}{\sqrt{tau_y}} $$


```{r model_3}
mod.alumni.3 <- "
model {

 for (i in 1:n) {
  y[i]~ dnorm(b0 + mat6*x1[i] + leng4*x2[i] + leng6*x3[i] + ing4*x4[i] + ing6*x5[i] + publica*x6[i] + sexo*x9[i] + interaccion*x2[i]*x9[i], tau_y)
 }
 
 b0 ~ dnorm(0, 1)
 mat6 ~ dnorm(0, 1)  
 leng4 ~ dnorm(0, 1)
 leng6 ~ dnorm(0, 1)
 ing4 ~ dnorm(0, 1)
 ing6 ~ dnorm(0, 1)
 publica ~ dnorm(0, 1)
 sexo ~ dnorm(0, 1)
 interaccion ~ dnorm(0, 1)

 tau_y ~ dgamma(0.001, 0.001)
 sigma_y <- 1/sqrt(tau_y)

}
"

Iter <- 5000
Burn <- 400
Chain <- 2
Thin <- 1 #per eliminare l'effetto dell'autocorrelazione delle simulazioni

data.3 <- with(train, list(y = PMAT_4, x1 = PMAT_6, x2=PLENG_4, x3=PLENG_6, x4=PANG_4, x5=PANG_6, x6=NATURALESA_Pública, x9=GENERE_H, n = dim(train)[1]))

parameters.3 <- c("b0", "mat6", "leng4", "leng6", "ing4", "ing6", "publica", "sexo", "interaccion", "sigma_y")

initials.3=list(list(b0 = 3, mat6 = 1, leng4= 0.1, leng6=0, ing4=0, ing6=0, publica=0,sexo=0, interaccion=0,
                   tau_y = 4),
              list(b0 = 2, mat6 = 1.5, leng4= 0.3, leng6=0, ing4=1, ing6=1, publica=1, sexo=1, interaccion=1,
                   tau_y = 2))
```

### Simulación de modelo 3

También en este caso se simula el modelo ya que una resolución analítica requeriría un esfuerzo computacional más que considerable.

```{r sim_model_3, cache=T, results='hide'}
alumni.sim.3 <- jags(data.3, inits=initials.3, parameters.to.save=parameters.3, 
		  n.iter=(Iter*Thin+Burn),n.burnin=Burn, n.thin=Thin, n.chains=Chain, 
		  model=textConnection(mod.alumni.3))
```

```{r trace_model3}
par(mar = c(2, 2, 2, 2))
traceplot(alumni.sim.3, mfrow = c(4,3), varname = parameters.3, col=c("black","red"), ask=F)
```


Como puede verse también en este caso el modelo converge.

### Interpretación y validación de los modelos 3

También en este modelo recordamos que los coeficientes relativos a los resultados escolares se obtienen como diferencia de la media relativa al examen. Observamos que son valores muy cercanos a 0 pero a pesar de esto las distribuciones no contienen 0 en el intervalo de confianza del 95%. Por lo tanto, todas las covariables son significativas.

```{r print_mod3, results='hide'}
print(alumni.sim.3, digits=2)
```


```{r CI_model3}
output = alumni.sim.3
significance = !(output$BUGSoutput$summary[,3]<0 & output$BUGSoutput$summary[,7]>0)
# print(significance)

linea = which(rownames(output$BUGSoutput$summary)=="deviance")
confid.inter = output$BUGSoutput$summary[-linea,c(3,7,1)]

par(mfrow=c(1,1), mar = c(6, 3, 2, 1))
plot(1:length(confid.inter[,1]), confid.inter[,3], col="grey", pch=16, axes = F, xlab="", ylab="", ylim = c(-3,11), main = "Intervalo de confianza del 95% para los coeficientes")
segments(x0=1:length(confid.inter[,1]), y0 = confid.inter[,1], x1 = 1:length(confid.inter[,1]), y1 = confid.inter[,2], lty = 2)
points(1:length(confid.inter[,1]), confid.inter[,3], col="grey", pch=16)
box()
axis(1, 1:length(rownames(confid.inter)), rownames(confid.inter), las = 2)
axis(2, -3:11, -3:11)
points(1:length(confid.inter[,1]), confid.inter[,2], col="red", pch=16)
points(1:length(confid.inter[,1]), confid.inter[,1], col="blue", pch=16)
abline(h=0, lty=2)
```


También en este caso analizamos las estadísticas de los percentiles 25%, 50%, 75%. Nos referimos siempre a la distribución real de las notas obtenidas por los alumnos.


```{r prediction_3}
M = 4000
# M = 10
set.seed(2023)
id_test_pred = sample(1:dim(test)[1],M)
test_pred = test[id_test_pred,-c(2,3,10, 11)]
X = cbind(rep(1,n),as.matrix(test_pred), as.matrix(test_pred$PLENG_4*(test_pred$GENERE_H)))

C = confid.inter[,3]
C = C[c("b0", "mat6", "leng4", "leng6", "ing4", "ing6", "publica", "sexo", "interaccion")]

# y_t <- rtruncnorm(M,0,100, X %*% C, confid.inter["sigma_y",3])
y_t = rnorm(M, X %*% C, confid.inter["sigma_y",3]) + m4
#y_t <- rtruncnorm(M, a = -m4 ,b = 100-m4, X %*% C, confid.inter["sigma_y",3]) + m4
per <- quantile(y_t, c(0.25, 0.5, 0.75))
# print(per)
```

```{r stat_comparison3, message=FALSE}
real <- quantile(train$PMAT_4+m4, c(0.25, 0.5, 0.75))

ggplot() +
  geom_histogram(data=train, aes(x = PMAT_4+m4, y=..density..), color = "grey", fill = "royalblue3") +
  ggtitle("Comparación entre la distribución PMAT_4 y el valor obtenido por las estadísticas", ) +
  geom_vline(xintercept=per[1], linetype="dashed", color = "red", size = 1) +
  geom_vline(xintercept=per[2], linetype="dashed", color = "red", size = 1) + 
  geom_vline(xintercept=per[3], linetype="dashed", color = "red", size = 1) + 
  geom_vline(xintercept=real[1], linetype="dashed", color = "blue", size = 0.5) +
  geom_vline(xintercept=real[2], linetype="dashed", color = "blue", size = 0.5) + 
  geom_vline(xintercept=real[3], linetype="dashed", color = "blue", size = 0.5) + 
  ylab("Densidad") +
  xlab("Nota") 
```

Las estadísticas siempre están a la izquierda de las estadísticas reales, pero aún consideramos que el modelo es satisfactorio y sin una pérdida significativa de descriptividad en comparación con el modelo inicial, que era mucho más pesado.
Comparando también los índices DIC vemos que los modelos tienen los siguientes valores mod_1 = `r round(alumni.sim.1$BUGSoutput$DIC,2)` , mod_2 = `r round(alumni.sim.2$BUGSoutput$DIC,2)` and mod_3 = `r round(alumni.sim.3$BUGSoutput$DIC,2)`. Les recordamos que para el índice DIC más bajo es mejor por lo que confirmamos la elección del modelo 3.
\
Así que vamos a analizarlo en detalle.




\newpage 

# Implementación del modelo

```{r prep_mod3}
load("alumni.Rdata")
alumni$AREA_TERRITORIAL[alumni$AREA_TERRITORIAL == "Maresme Vallès Oriental" | alumni$AREA_TERRITORIAL == "Maresme-Vallès Oriental"] = "Maresme - Vallès Oriental" 

alumni$AREA_TERRITORIAL = factor(alumni$AREA_TERRITORIAL)

names(alumni)[4] = "HABITAT"
alumni = dummy_cols(alumni, select_columns = c("NATURALESA", "GENERE", "HABITAT"), remove_first_dummy = T, remove_selected_columns = T)
areas = dummy_cols(data.frame(Area = alumni$AREA_TERRITORIAL), remove_first_dummy = T, remove_selected_columns = T)
names(areas)=levels(alumni$AREA_TERRITORIAL)[-1]
m=dim(areas)[2]

m4 = mean(alumni$PMAT_4)

alumni$PLENG_6 = alumni$PLENG_6 - mean(alumni$PLENG_6)  # Plen_6  = delta_pl_6
alumni$PLENG_4 = alumni$PLENG_4 - mean(alumni$PLENG_4)  # Plen_6  = delta_pl_6
alumni$PANG_6 = alumni$PANG_6 - mean(alumni$PANG_6)  # Plen_6  = delta_pa_6
alumni$PANG_4 = alumni$PANG_4 - mean(alumni$PANG_4)  # Plen_6  = delta_pa_4
alumni$PMAT_6 = alumni$PMAT_6 - mean(alumni$PMAT_6)  # Plen_6  = delta_pa_6
alumni$PMAT_4 = alumni$PMAT_4 - mean(alumni$PMAT_4)  # Plen_6  = delta_pa_6

n = round(0.8*dim(alumni)[1])
set.seed(1234)
id_train = sample(1:length(alumni$PMAT_6), replace = F, size = n)
train = alumni[id_train, ]
test = alumni[-id_train, ]

areas_train = areas[id_train, ]
areas_test = areas[-id_train, ]

```

```{r model_3_big, message=FALSE}
mod.alumni.3 <- "
model {

 for (i in 1:n) {
  y[i]~ dnorm(b0 + mat6*x1[i] + leng4*x2[i] + leng6*x3[i] + ing4*x4[i] + ing6*x5[i] + publica*x6[i] + sexo*x9[i] + interaccion*x2[i]*x9[i], tau_y)
 }
 
 b0 ~ dnorm(0, 1)
 mat6 ~ dnorm(0, 1)  
 leng4 ~ dnorm(0, 1)
 leng6 ~ dnorm(0, 1)
 ing4 ~ dnorm(0, 1)
 ing6 ~ dnorm(0, 1)
 publica ~ dnorm(0, 1)
 sexo ~ dnorm(0, 1)
 interaccion ~ dnorm(0, 1)

 tau_y ~ dgamma(0.001, 0.001)
 sigma_y <- 1/sqrt(tau_y)

}
"

Iter <- 5000
Burn <- 400
Chain <- 2
Thin <- 1 #per eliminare l'effetto dell'autocorrelazione delle simulazioni

data.3 <- with(train, list(y = PMAT_4, x1 = PMAT_6, x2=PLENG_4, x3=PLENG_6, x4=PANG_4, x5=PANG_6, x6=NATURALESA_Pública, x9=GENERE_H, n = dim(train)[1]))

parameters.3 <- c("b0", "mat6", "leng4", "leng6", "ing4", "ing6", "publica", "sexo", "interaccion", "sigma_y")

initials.3=list(list(b0 = 3, mat6 = 1, leng4= 0.1, leng6=0, ing4=0, ing6=0, publica=0,sexo=0, interaccion=0,
                   tau_y = 4),
              list(b0 = 2, mat6 = 1.5, leng4= 0.3, leng6=0, ing4=1, ing6=1, publica=1, sexo=1, interaccion=1,
                   tau_y = 2))
```

Analicemos ahora el modelo 3 en detalle. Dado que es un modelo más ligero, podemos entrenarlo en una mayor parte de los estudiantes. Usamos un conjunto de entrenamiento esta vez compuesto por el 80% de los estudiantes (alrededor de $37 \ 000$).
\
También en este caso simulamos el modelo a través del paquete JAGS generando MCMCs. Al igual que en los modelos anteriores, aquí también convergen las dos cadenas de prueba
\
Los coeficientes resultantes de este modelo son siempre significativos. También notamos que la variabilidad de las distribuciones es menor gracias al mayor tamaño del conjunto de datos de entrenamiento.


```{r sim_model_3_big, cache=T, results='hide', message=FALSE}
alumni.sim.3_big <- jags(data.3, inits=initials.3, parameters.to.save=parameters.3, 
		  n.iter=(Iter*Thin+Burn),n.burnin=Burn, n.thin=Thin, n.chains=Chain, 
		  model=textConnection(mod.alumni.3))
```

```{r trace_model3_big, results='hide', message=FALSE}
par(mar = c(2, 2, 2, 2))
traceplot(alumni.sim.3_big, mfrow = c(4,3), varname = parameters.3, col=c("black","red"), ask=F)
```



```{r CI_model3_big}
output = alumni.sim.3_big
significance = !(output$BUGSoutput$summary[,3]<0 & output$BUGSoutput$summary[,7]>0)
# print(significance)

linea = which(rownames(output$BUGSoutput$summary)=="deviance")
confid.inter = output$BUGSoutput$summary[-linea,c(3,7,1)]

par(mfrow=c(1,1), mar = c(6, 3, 2, 1))
plot(1:length(confid.inter[,1]), confid.inter[,3], col="grey", pch=16, axes = F, xlab="", ylab="", ylim = c(-3,11), main = "Intervalo de confianza del 95% para los coeficientes")
segments(x0=1:length(confid.inter[,1]), y0 = confid.inter[,1], x1 = 1:length(confid.inter[,1]), y1 = confid.inter[,2], lty = 2)
points(1:length(confid.inter[,1]), confid.inter[,3], col="grey", pch=16)
box()
axis(1, 1:length(rownames(confid.inter)), rownames(confid.inter), las = 2)
axis(2, -3:11, -3:11)
points(1:length(confid.inter[,1]), confid.inter[,2], col="red", pch=16)
points(1:length(confid.inter[,1]), confid.inter[,1], col="blue", pch=16)
abline(h=0, lty=2)
```


Los valores numéricos de los coeficientes y todos los rangos se pueden ver en la tabla de coeficientes del anexo.

Aquí presentamos un análisis de los valores medios obtenidos de la distribución de los coeficientes:

* $b_0 = `r round(alumni.sim.3_big$BUGSoutput$summary[1,1],2)`$: El intercepto es negativo, así que supongamos que un estudiante promedio (covariables numéricas = 0), mujer, en una escuela privada obtendrá una calificación más baja que el promedio en el examen mat4.

* $ing4 = `r round(alumni.sim.3_big$BUGSoutput$summary[3,1],2)`$: Para la calificación de inglés en el examen Quart el coeficiente es negativo por lo que podemos suponer que una persona que está por encima del promedio en inglés tampoco estará por encima del promedio en matemáticas.

* $ing6 = `r round(alumni.sim.3_big$BUGSoutput$summary[4,1],2)`$: El coeficiente en este caso es positivo, por lo que un alumno que haya obtenido un buen resultado en inglés en el examen Sisè tenderá a tener un buen resultado también en matemáticas.

* $interaccion = `r round(alumni.sim.3_big$BUGSoutput$summary[5,1],2)`$: El valor del coeficiente es negativo. Esto significa que un estudiante varón tenderá a tener un desempeño más bajo en lenguaje que en matemáticas que el estudiante promedio. Este resultado es aún más interesante cuando se compara con el de leng4 ya que el coeficiente se vuelve negativo en promedio para leng4. De acuerdo con el modelo, por lo tanto, un estudiante varón tiene un desempeño opuesto al promedio en los dos exámenes.

* $leng4 = `r round(alumni.sim.3_big$BUGSoutput$summary[6,1],2)`$: El coeficiente es positivo, teniendo en cuenta la interacción significa que una niña que en promedio obtiene buenos resultados en lenguaje en el examen de Quart también tendrá un resultado por encima del promedio en el examen de matemáticas del mismo año. 

* $leng6 = `r round(alumni.sim.3_big$BUGSoutput$summary[7,1],2)`$: Siendo positivo el resultado de mate4 es consistente con el de leng 6 con respecto a la media.

* $mate6 = `r round(alumni.sim.3_big$BUGSoutput$summary[8,1],2)`$: También en este caso el coeficiente es positivo por lo que el resultado de las dos pruebas está de acuerdo. También notamos que el coeficiente es el más grande entre los presentes. La marca de mat6 con respecto a la media es, por tanto, la mayor contribución a la hora de predecir el resultado de mat4.

* $publica = `r round(alumni.sim.3_big$BUGSoutput$summary[9,1],2)`$: El coeficiente también es positivo en este caso. Al ser una variable binaria podemos considerar que un alumno de un colegio público obtendrá una nota media superior a este valor en comparación con el mismo alumno de un colegio privado.

* $sexo = `r round(alumni.sim.3_big$BUGSoutput$summary[10,1],2)`$: También en este caso la variable es binaria por lo que observamos que un alumno varón obtendrá un resultado medio 2,5 puntos superior al de una chica.

* $sigma_y = `r round(alumni.sim.3_big$BUGSoutput$summary[11,1],2)`$: El valor estimado para la varianza de la distribución es bajo y parece ser un valor probable.


Ahora usamos el modelo obtenido para simular los resultados obtenidos en el conjunto de prueba. Usamos los coeficientes promedio para la simulación y extraemos un valor aleatorio de cada distribución generada para un estudiante.
\
La distribución resultante es la siguiente.


```{r}
M = dim(test)[1]
# M = 10
set.seed(2023)
id_test_pred = sample(1:dim(test)[1],M)
test_pred = test[id_test_pred,-c(2,3,10, 11)]
X = cbind(rep(1,n),as.matrix(test_pred), as.matrix(test_pred$PLENG_4*(test_pred$GENERE_H)))

C = confid.inter[,3]
C = C[c("b0", "mat6", "leng4", "leng6", "ing4", "ing6", "publica", "sexo", "interaccion")]

# y_t <- rtruncnorm(M,0,100, X %*% C, confid.inter["sigma_y",3])
y_t = rnorm(M, X %*% C, confid.inter["sigma_y",3]) + m4
y_t <- rtruncnorm(M, a = -m4 ,b = 100-m4, X %*% C, confid.inter["sigma_y",3]) + m4
per <- quantile(y_t, c(0.25, 0.5, 0.75))
# print(per)
```



```{r message=FALSE}
ggplot() +
  geom_histogram(data=data.frame(y_t), aes(x=y_t, y=..density..), colour="royalblue3", fill="royalblue3",binwidth=1) +
  geom_density(data=train, aes(x = PMAT_4+m4), color = "red") +
  ggtitle("Comparision between predictive posterior and PMAT_4 distribution", ) + 
  ylab("Density") +
  xlab("Nota") 
```

Vemos que sigue bastante de cerca la distribución teórica, por lo que estamos satisfechos con este modelo.



\newpage

# Conclusions

**Explicación rápida para nosotros:**

El último modelo es el que se elige. A partir de este modelo podemos responder a nuestro objetivo del proyecto:

**Toda esta conclusión debe ser explicada en términos de diferencia con el resultado medio ya que nuestros covatiados se refieren a la diferencia con la media**

- 1 ¿Es el género un factor relevante en el resultado de matemáticas?

Sí lo es, tenemos que hacer alguna prueba para confirmar esto, pero el coeficiente de sexo muestra que los niños deberían obtener un promedio de 2,52 puntos más que las niñas en el examen.

- 2 ¿Es cierto que las chicas son coherentes en las notas de longitud y matemáticas mientras que los chicos tienden a tener un comportamiento opuesto?

Sí, el coeficiente de leng4 muestra que para las niñas el resultado es el mismo tanto para leng como para matemáticas. \
Mientras que si para los niños la interacción reduce este coeficiente y se vuelve negativo (0.11 - 0.18 = -0.07), para los niños el resultado de las matemáticas está inversamente correlacionado con el resultado de la lengua.





\newpage
# Apéndice
## Código R
## Tablas parámetros estimados
```{r print_mod3_big}
print(alumni.sim.3_big, digits=2)

# round(alumni.sim.3_big$BUGSoutput$summary[1,1],2)
```
\newpage
# Referencias